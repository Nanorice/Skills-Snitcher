{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T16:18:15.430777Z",
     "start_time": "2020-07-26T16:18:14.602554Z"
    }
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from functools import reduce, wraps\n",
    "from typing import List, Set, Generator, Dict, Pattern, Tuple\n",
    "from collections import namedtuple\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T16:18:16.524748Z",
     "start_time": "2020-07-26T16:18:16.495685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why Superdrug\\n\\nPassionate about Beauty and Health? Want to be part of an innovative, trend setting retailer? Our vibrant Head Office, based by East Croydon station is a fantastic environment filled with hundreds of brilliant personalities.\\n\\nWe're a team that puts our customers and our teams at the heart of everything we do. At Superdrug, we aim to be the best in accessible health & beauty, loved by our customers for value, choice, friendly advice, service and fun.\\n\\nOur success comes from our people - they make the difference. We're all about personality, we have fun, and we work hard to deliver That Superdrug feeling.\\n\\nHere's the exciting bit...a day includes\\n\\nTo provide financial information and analytical support to the Store Operations and People teams to enable them to deliver their company targets and business profitability. The role focuses mainly around store wages but there is plenty of opportunity to get involved in all aspects of the retail business.\\n\\nKey Responsibilities\\n\\nPreparation of weekly and monthly hours and wage cost reporting.Hours and related spend tracking is vital to success of maintaining control of one of the largest cost lines in the business. It allows us to form early warning signals to the business, and also allows us to ensure the right stores have the right ability to provide the best service to our customers.Provide analysis on Wages to various internal stakeholders such as Store Operations, People and Finance teams.Proactive analysis of performance by region, area and store\\noAcross 6 regions, 51 areas and 800+ stores, it is vital the operational teams have everything they need to understand their cost base and ways we can influence spend.\\nLiaison with commercial teams to ensure timely accounting of supplier funding which has been raised for supplier driven initiatives in storeSupport the budgeting and forecasting processes providing quarterly forecasts and annual budgets\\noWe do 3 forecasts a year, alongside a corporate budgeting process. These are key to understanding our spend and allowing a future view of trends and spend.\\nIdentify and deliver developments in reporting to ensuring they deliver robust business information in an efficient manner to support store operations\\n\\nWhat you'll need to succeed\\n\\nPart Qualified CIMA/ACCA/ACA preferredRetail/FMCG experience from medium or large company preferredStrong Excel skills with VBA preferable and ability to master technical skills quickly, Access knowledge would be an advantageHigh attention to detailStrong communication skillsExperience of working in an analytical environment dealing with large data setsAbility to summarise detailed data and present it clearly for all levels of the businessAbility to prioritise and manage parallel workflows with tight deadlines\\n\\nHere's what's in it for you\\n\\n33 days holiday rising to 38 days with length of service (inclusive of bank holidays)\\nBeing part of more! We are part of a group who work closely with Savers, The Perfume Shop and Three UK.\\nWe are part of A.S. Watson Group, the world's largest international health and beauty retailer with over 15,700 stores in 25 markets!\\n2 staff discount codes for yourself and a family member or friend\\n30% discount on Superdrug Own Brand Products both in store and online\\nWorking in a stylish, modern and collaborative office close to East Croydon Station\\nCompany pension matching and bonus\\nUnrivalled Learning and Development programmes\\n\\nCome and be part of something special.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data + inspect description\n",
    "df = pd.read_csv('../skills-ml/data/indeed_finance_telecom_600.csv', index_col=0).reset_index(drop = True)\n",
    "t = df['full_info'][20]\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T16:20:17.421026Z",
     "start_time": "2020-07-26T16:20:17.418486Z"
    }
   },
   "outputs": [],
   "source": [
    "transforms = ['nlp_a']\n",
    "BULLET_CHARACTERS = ['+', '*', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T16:20:18.066304Z",
     "start_time": "2020-07-26T16:20:18.050221Z"
    },
    "code_folding": [
     2,
     28,
     50
    ]
   },
   "outputs": [],
   "source": [
    "Span = namedtuple(\"Span\", [\"text\", \"start_index\"])\n",
    "\n",
    "def sentence_tokenize(text: str, include_spans: bool=False) -> List:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        text (str): a unicode string\n",
    "    Returns:\n",
    "        list: tokenized sentence. If include_spans is True, then each item is a Span object  \n",
    "        with both text and a start_index. Otherwise, only text is returned.\n",
    "    \"\"\"\n",
    "    lines = re.split('\\n', text)\n",
    "    #lines = list(filter(None, sentences))\n",
    "    sentences = []\n",
    "    \n",
    "    tokenizer = PunktSentenceTokenizer()\n",
    "    total_offset = 0\n",
    "    for line in lines:\n",
    "        line_start = total_offset\n",
    "        for sentence_start, sentence_end in tokenizer.span_tokenize(line):\n",
    "            sentence = line[sentence_start:sentence_end]\n",
    "            if include_spans:\n",
    "                sentences.append(Span(text=sentence, start_index=line_start + sentence_start))\n",
    "            else:\n",
    "                sentences.append(sentence)\n",
    "            total_offset = line_start + sentence_end\n",
    "        total_offset += 1\n",
    "    return sentences\n",
    "\n",
    "def split_by_bullets(sentence: str) -> List[Span]:\n",
    "    \"\"\"Split sentence by bullet characters\n",
    "    Args:\n",
    "        sentence (str)\n",
    "    Returns: List of Span objects representing the text inbetween bullets, with both text and start indices\n",
    "    \"\"\"\n",
    "    units = []\n",
    "    for bullet_char in BULLET_CHARACTERS:\n",
    "        index = 0\n",
    "        padded_bullet = bullet_char + ' '\n",
    "        if sentence.count(padded_bullet) > 1:\n",
    "            for i, fragment in enumerate(sentence.split(padded_bullet)):\n",
    "                if i > 0:\n",
    "                    units.append(Span(text=padded_bullet + fragment, start_index=index))\n",
    "                    index += len(padded_bullet + fragment)\n",
    "                else:\n",
    "                    units.append(Span(text=fragment, start_index=index))\n",
    "                    index += len(fragment)\n",
    "            return units\n",
    "    units.append(Span(text=sentence, start_index=0))\n",
    "    return units\n",
    "\n",
    "def strip_bullets_from_line(line: str) -> str:\n",
    "    \"\"\"Remove bullets from beginning of line\"\"\"\n",
    "    for bullet_char in BULLET_CHARACTERS:\n",
    "        if line.startswith(bullet_char):\n",
    "            line = line.replace(bullet_char, '')\n",
    "    return line\n",
    "\n",
    "def section_extract(section_regex: Pattern, document: str) -> List[Span]:\n",
    "    \"\"\"Only return the contents of the configured section heading\n",
    "    Defines a 'heading' as the text of a sentence that:\n",
    "        - does not itself start with a bullet character\n",
    "        - either has between 1 and 4 words or ends in a colon or question mark\n",
    "    For a heading that matches the given pattern, returns each sentence between it and the next heading.\n",
    "    Heavily relies on the fact that sentence_tokenize does line splitting\n",
    "    as well as standard sentence tokenization. In this way, it should work both\n",
    "    for text strings that have newlines and for text strings that don't.\n",
    "    In addition, this function splits each sentence by bullet characters as often bullets denote\n",
    "    what we want to call 'sentences', but authors often take advantage of the bullet characters\n",
    "    to make the contents of each 'sentence' into small sentence fragments, which makes standard\n",
    "    sentence tokenization insufficient if the newlines have been taken out.\n",
    "    Args:\n",
    "        section_regex (Pattern), A regular expression defining the heading/s you want to include\n",
    "        document (str) The text to search in\n",
    "    Returns: List of Span objects with both the text and a start_index\n",
    "    \"\"\"\n",
    "    units_in_section = []\n",
    "    if not document:\n",
    "        return units_in_section\n",
    "    sentences = sentence_tokenize(document, include_spans=True)\n",
    "    units = [\n",
    "        Span(text=unit.text, start_index=sentence.start_index + unit.start_index)\n",
    "        for sentence in sentences\n",
    "        for unit in split_by_bullets(sentence.text)\n",
    "    ]\n",
    "\n",
    "    heading = ''\n",
    "    for unit in units:\n",
    "        words_in_unit = len(unit.text.lstrip().rstrip().split(' '))\n",
    "        if unit.text.strip() and unit.text[0] not in BULLET_CHARACTERS and ((words_in_unit > 0 and words_in_unit < 6) or unit.text.endswith((':', '?'))):\n",
    "            heading = unit.text\n",
    "        if re.match(section_regex, heading) and unit.text != heading and len(unit.text.strip()) > 0:\n",
    "            stripped = strip_bullets_from_line(unit.text).lstrip().rstrip()\n",
    "\n",
    "            units_in_section.append(Span(\n",
    "                text=stripped,\n",
    "                start_index=unit.start_index + unit.text.index(stripped)\n",
    "            ))\n",
    "    return units_in_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T17:18:31.520104Z",
     "start_time": "2020-07-26T17:18:31.513081Z"
    }
   },
   "outputs": [],
   "source": [
    "def section_extract_str(section_regex: Pattern, document: str) -> str:\n",
    "    units_in_section_str = []\n",
    "    if not document:\n",
    "        return document\n",
    "    sentences = sentence_tokenize(document, include_spans=True)\n",
    "    units = [\n",
    "        Span(text=unit.text, start_index=sentence.start_index + unit.start_index)\n",
    "        for sentence in sentences\n",
    "        for unit in split_by_bullets(sentence.text)\n",
    "    ]\n",
    "\n",
    "    heading = ''\n",
    "    for unit in units:\n",
    "        words_in_unit = len(unit.text.lstrip().rstrip().split(' '))\n",
    "        if unit.text.strip() and unit.text[0] not in BULLET_CHARACTERS and ((words_in_unit > 0 and words_in_unit < 6) or unit.text.endswith((':', '?', '...'))):\n",
    "#         if unit.text.strip() and unit.text[0] not in BULLET_CHARACTERS and (words_in_unit > 0 and words_in_unit < 6):\n",
    "            heading = unit.text\n",
    "        if re.match(section_regex, heading) and unit.text != heading and len(unit.text.strip()) > 0:\n",
    "            stripped = strip_bullets_from_line(unit.text).lstrip().rstrip()\n",
    "            units_in_section_str.append(stripped)\n",
    "    res = ' '.join(map(str, units_in_section_str))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T17:18:33.182319Z",
     "start_time": "2020-07-26T17:18:32.723734Z"
    }
   },
   "outputs": [],
   "source": [
    "section_regex = r'.*([Qq]ualifications|[Ss]kills|[Rr]equirements|[Ab]ilities|[Cc]ompetencies|[Nn]eed|succeed|[Cc]andidate|looking for|[Ss]uccessful|must have|suitable|[Ww]ho)'\n",
    "df['section_str'] = df['full_info'].apply(lambda x: section_extract_str(section_regex, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T18:03:23.947217Z",
     "start_time": "2020-07-26T18:03:23.943879Z"
    }
   },
   "outputs": [],
   "source": [
    "df['check'] = df['section_str'] == ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T18:22:03.085893Z",
     "start_time": "2020-07-26T18:22:03.080496Z"
    }
   },
   "outputs": [],
   "source": [
    "# df[df['check']==True]['section_str'] = 'a'\n",
    "df.loc[df['check']==True, 'section_str'] = df.loc[df['check']==True, 'full_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T18:28:58.338388Z",
     "start_time": "2020-07-26T18:28:58.333653Z"
    }
   },
   "outputs": [],
   "source": [
    "df['onet_code'] = None\n",
    "df.loc[0:300, 'onet_code'] = '13-2099.01'\n",
    "df.loc[300:600, 'onet_code'] = '17-3023.00'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T17:18:33.319968Z",
     "start_time": "2020-07-26T17:18:33.304894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_title</th>\n",
       "      <th>summary</th>\n",
       "      <th>full_info</th>\n",
       "      <th>ref</th>\n",
       "      <th>section_str</th>\n",
       "      <th>check</th>\n",
       "      <th>onet_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walworth</td>\n",
       "      <td>TAB Asset Management</td>\n",
       "      <td>WORKING FROM HOME - Trainee Financial Broker</td>\n",
       "      <td>Long term career in wealth management.\\nFundin...</td>\n",
       "      <td>We have an exciting opportunity to join our Fi...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=6b73c632767df...</td>\n",
       "      <td>Appreciation of the needs of internal and exte...</td>\n",
       "      <td>False</td>\n",
       "      <td>13-2099.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London</td>\n",
       "      <td>Walterton &amp; Elgin Community Homes</td>\n",
       "      <td>Accounts Assistant</td>\n",
       "      <td>Experience in a finance or accounting role (de...</td>\n",
       "      <td>You're the brains behind our work.\\nYou're rea...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=ff1d0f140be90...</td>\n",
       "      <td>You're the brains behind our work.\\nYou're rea...</td>\n",
       "      <td>True</td>\n",
       "      <td>13-2099.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mayfair</td>\n",
       "      <td>Harris Federation</td>\n",
       "      <td>Finance Administrative Assistant - Part Time</td>\n",
       "      <td>We are currently looking to appoint a Finance ...</td>\n",
       "      <td>Main functions of the job: The reconciliation ...</td>\n",
       "      <td>https://www.indeed.com/company/United-Bank-UK/...</td>\n",
       "      <td>Main functions of the job: The reconciliation ...</td>\n",
       "      <td>True</td>\n",
       "      <td>13-2099.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>London EC1V</td>\n",
       "      <td>HANetf</td>\n",
       "      <td>London Based Finance assetmanagement fund Sale...</td>\n",
       "      <td>We are looking for several interns to help sup...</td>\n",
       "      <td>We are looking for a Junior Finance Analyst wi...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=c9c4725473750...</td>\n",
       "      <td>A part-qualified accountant (CIMA, ACCA, ACA o...</td>\n",
       "      <td>False</td>\n",
       "      <td>13-2099.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London</td>\n",
       "      <td>Abellio London</td>\n",
       "      <td>Finance Assistant</td>\n",
       "      <td>The successful applicant will report to the Fi...</td>\n",
       "      <td>Company\\nBrookfield is a global alternative as...</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=0dbd9eb04d38e...</td>\n",
       "      <td>Raise POs for Global Shared Service Manager co...</td>\n",
       "      <td>False</td>\n",
       "      <td>13-2099.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      location                       company_name  \\\n",
       "0     Walworth               TAB Asset Management   \n",
       "1       London  Walterton & Elgin Community Homes   \n",
       "2      Mayfair                  Harris Federation   \n",
       "3  London EC1V                             HANetf   \n",
       "4       London                     Abellio London   \n",
       "\n",
       "                                           job_title  \\\n",
       "0       WORKING FROM HOME - Trainee Financial Broker   \n",
       "1                                 Accounts Assistant   \n",
       "2       Finance Administrative Assistant - Part Time   \n",
       "3  London Based Finance assetmanagement fund Sale...   \n",
       "4                                  Finance Assistant   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Long term career in wealth management.\\nFundin...   \n",
       "1  Experience in a finance or accounting role (de...   \n",
       "2  We are currently looking to appoint a Finance ...   \n",
       "3  We are looking for several interns to help sup...   \n",
       "4  The successful applicant will report to the Fi...   \n",
       "\n",
       "                                           full_info  \\\n",
       "0  We have an exciting opportunity to join our Fi...   \n",
       "1  You're the brains behind our work.\\nYou're rea...   \n",
       "2  Main functions of the job: The reconciliation ...   \n",
       "3  We are looking for a Junior Finance Analyst wi...   \n",
       "4  Company\\nBrookfield is a global alternative as...   \n",
       "\n",
       "                                                 ref  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=6b73c632767df...   \n",
       "1  https://www.indeed.com/rc/clk?jk=ff1d0f140be90...   \n",
       "2  https://www.indeed.com/company/United-Bank-UK/...   \n",
       "3  https://www.indeed.com/rc/clk?jk=c9c4725473750...   \n",
       "4  https://www.indeed.com/rc/clk?jk=0dbd9eb04d38e...   \n",
       "\n",
       "                                         section_str  check   onet_code  \n",
       "0  Appreciation of the needs of internal and exte...  False  13-2099.01  \n",
       "1  You're the brains behind our work.\\nYou're rea...   True  13-2099.01  \n",
       "2  Main functions of the job: The reconciliation ...   True  13-2099.01  \n",
       "3  A part-qualified accountant (CIMA, ACCA, ACA o...  False  13-2099.01  \n",
       "4  Raise POs for Global Shared Service Manager co...  False  13-2099.01  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T17:18:51.235041Z",
     "start_time": "2020-07-26T17:18:51.231430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product & Applications EngineerLocation: LondonSalary: Negotiable depending on experienceCompany: Origin are pleased to announce our client is a market-leading telecom tower infrastructure company, are looking to add a Product & Applications Engineer to their team on a permanent full-time basis.Duties and Responsibilities: The Product and Applications Engineer is responsible for providing the technical support to enable Projects, Operations and Performance Engineering teams to operate safely and efficiently with the existing power equipment and the introduction of new power products into the network as it grows.You will be a technical lead on electrical design, assisting the sales & marketing on the power design for new telecom rollouts and the supply chain team for the selection of new supplier.Standby DC power assets including rectifier and batteriesSite power generation including solar and diesel generatorsElectrical AC and DC site designController configuration filesField Operating Procedures and Product Information bulletinsProduct Specification, Statement of Conformance and RFQ documentationTechnical due diligence on suppliers and acquisitionsEvaluate cost benefits of new technologies for business casesNew product trials and initial product roll outsTechnical support for Performance EngineeringThird level technical support to field operationsEngage suppliers for technical product support and new product developmentsEssential RequirementsHND/Degree in Electrical / Electronic Engineering or other relevant subjectMinimum of 1-2 years in Telecom Power engineering with a telecom operator or rectifier / battery / installation supplierSmall ?48VDC Rectifier Power Systems in Grid and Off Grid applicationsLarge DC & AC Standby Power Systems in DatacentresIT Networking (http, snmp, Modbus, IoT)Microsoft Office productsAvailable for Travel internationally up to 25%Desirable RequirementsElectrical Installations BS7671 (City & Guilds 2382)Electrical Inspection & Testing (City & Guilds 2391)Basic programming (VBA, Java)Solar and other renewable energy sourcesLithium batteriesHave worked in Africa and its associated market challengesUnderstanding of the GSM telecommunications industryBenefits: 12% discretionary target bonus, health and dental insurance, life insurance, subsidised gym membership and 9% employer pension contribution.To apply, please contact Marcus at Origin Multilingual (UK) or click apply below.Reference ID: BH10991Job Type: PermanentWork remotely:Temporarily due to COVID-19']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_info'][597].split('\\n')\n",
    "# t = df['full_info'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T17:14:18.276512Z",
     "start_time": "2020-07-26T17:14:18.268005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why Superdrug\n",
      "Passionate about Beauty and Health?\n",
      "Want to be part of an innovative, trend setting retailer?\n",
      "Key Responsibilities\n",
      "What you'll need to succeed\n",
      "Being part of more!\n",
      "We are part of A.S.\n",
      "Company pension matching and bonus\n",
      "Unrivalled Learning and Development programmes\n"
     ]
    }
   ],
   "source": [
    "document = t\n",
    "\n",
    "# section_regex = r'.*([Qq]ualifications|[Ss]kills|[Rr]equirements|[Ab]ilities|[Cc]ompetencies|[Nn]eed|succeed)'\n",
    "# section_regex = r'.*([Qq]ualifications|[Ss]kills|[Rr]equirements|[Ab]ilities|[Cc]ompetencies)'\n",
    "\n",
    "units_in_section = []\n",
    "\n",
    "sentences = sentence_tokenize(document, include_spans=True)\n",
    "units = [\n",
    "    Span(text=unit.text, start_index=sentence.start_index + unit.start_index)\n",
    "    for sentence in sentences\n",
    "    for unit in split_by_bullets(sentence.text)\n",
    "]\n",
    "\n",
    "heading = ''\n",
    "for unit in units:\n",
    "    words_in_unit = len(unit.text.lstrip().rstrip().split(' '))\n",
    "    if unit.text.strip() and unit.text[0] not in BULLET_CHARACTERS and ((words_in_unit > 0 and words_in_unit < 6) or unit.text.endswith((':', '?', '...'))):\n",
    "        heading = unit.text\n",
    "        print(heading)\n",
    "    if re.match(section_regex, heading) and unit.text != heading and len(unit.text.strip()) > 0:\n",
    "        stripped = strip_bullets_from_line(unit.text).lstrip().rstrip()\n",
    "#         print(unit.start_index + unit.text.index(stripped))\n",
    "        units_in_section.append(Span(\n",
    "            text=stripped,\n",
    "            start_index=unit.start_index + unit.text.index(stripped)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T17:14:19.654513Z",
     "start_time": "2020-07-26T17:14:19.651092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Span(text='Preparation of weekly and monthly hours and wage cost reporting.Hours and related spend tracking is vital to success of maintaining control of one of the largest cost lines in the business.', start_index=998),\n",
       " Span(text='It allows us to form early warning signals to the business, and also allows us to ensure the right stores have the right ability to provide the best service to our customers.Provide analysis on Wages to various internal stakeholders such as Store Operations, People and Finance teams.Proactive analysis of performance by region, area and store', start_index=1188),\n",
       " Span(text='oAcross 6 regions, 51 areas and 800+ stores, it is vital the operational teams have everything they need to understand their cost base and ways we can influence spend.', start_index=1532),\n",
       " Span(text='Liaison with commercial teams to ensure timely accounting of supplier funding which has been raised for supplier driven initiatives in storeSupport the budgeting and forecasting processes providing quarterly forecasts and annual budgets', start_index=1700),\n",
       " Span(text='oWe do 3 forecasts a year, alongside a corporate budgeting process.', start_index=1937),\n",
       " Span(text='These are key to understanding our spend and allowing a future view of trends and spend.', start_index=2005),\n",
       " Span(text='Identify and deliver developments in reporting to ensuring they deliver robust business information in an efficient manner to support store operations', start_index=2094),\n",
       " Span(text='Part Qualified CIMA/ACCA/ACA preferredRetail/FMCG experience from medium or large company preferredStrong Excel skills with VBA preferable and ability to master technical skills quickly, Access knowledge would be an advantageHigh attention to detailStrong communication skillsExperience of working in an analytical environment dealing with large data setsAbility to summarise detailed data and present it clearly for all levels of the businessAbility to prioritise and manage parallel workflows with tight deadlines', start_index=2275),\n",
       " Span(text=\"Here's what's in it for you\", start_index=2792),\n",
       " Span(text='33 days holiday rising to 38 days with length of service (inclusive of bank holidays)', start_index=2821)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units_in_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T17:09:44.891658Z",
     "start_time": "2020-07-26T17:09:44.887939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why Superdrug',\n",
       " '',\n",
       " 'Passionate about Beauty and Health? Want to be part of an innovative, trend setting retailer? Our vibrant Head Office, based by East Croydon station is a fantastic environment filled with hundreds of brilliant personalities.',\n",
       " '',\n",
       " \"We're a team that puts our customers and our teams at the heart of everything we do. At Superdrug, we aim to be the best in accessible health & beauty, loved by our customers for value, choice, friendly advice, service and fun.\",\n",
       " '',\n",
       " \"Our success comes from our people - they make the difference. We're all about personality, we have fun, and we work hard to deliver That Superdrug feeling.\",\n",
       " '',\n",
       " \"Here's the exciting bit...a day includes\",\n",
       " '',\n",
       " 'To provide financial information and analytical support to the Store Operations and People teams to enable them to deliver their company targets and business profitability. The role focuses mainly around store wages but there is plenty of opportunity to get involved in all aspects of the retail business.',\n",
       " '',\n",
       " 'Key Responsibilities',\n",
       " '',\n",
       " 'Preparation of weekly and monthly hours and wage cost reporting.Hours and related spend tracking is vital to success of maintaining control of one of the largest cost lines in the business. It allows us to form early warning signals to the business, and also allows us to ensure the right stores have the right ability to provide the best service to our customers.Provide analysis on Wages to various internal stakeholders such as Store Operations, People and Finance teams.Proactive analysis of performance by region, area and store',\n",
       " 'oAcross 6 regions, 51 areas and 800+ stores, it is vital the operational teams have everything they need to understand their cost base and ways we can influence spend.',\n",
       " 'Liaison with commercial teams to ensure timely accounting of supplier funding which has been raised for supplier driven initiatives in storeSupport the budgeting and forecasting processes providing quarterly forecasts and annual budgets',\n",
       " 'oWe do 3 forecasts a year, alongside a corporate budgeting process. These are key to understanding our spend and allowing a future view of trends and spend.',\n",
       " 'Identify and deliver developments in reporting to ensuring they deliver robust business information in an efficient manner to support store operations',\n",
       " '',\n",
       " \"What you'll need to succeed\",\n",
       " '',\n",
       " 'Part Qualified CIMA/ACCA/ACA preferredRetail/FMCG experience from medium or large company preferredStrong Excel skills with VBA preferable and ability to master technical skills quickly, Access knowledge would be an advantageHigh attention to detailStrong communication skillsExperience of working in an analytical environment dealing with large data setsAbility to summarise detailed data and present it clearly for all levels of the businessAbility to prioritise and manage parallel workflows with tight deadlines',\n",
       " '',\n",
       " \"Here's what's in it for you\",\n",
       " '',\n",
       " '33 days holiday rising to 38 days with length of service (inclusive of bank holidays)',\n",
       " 'Being part of more! We are part of a group who work closely with Savers, The Perfume Shop and Three UK.',\n",
       " \"We are part of A.S. Watson Group, the world's largest international health and beauty retailer with over 15,700 stores in 25 markets!\",\n",
       " '2 staff discount codes for yourself and a family member or friend',\n",
       " '30% discount on Superdrug Own Brand Products both in store and online',\n",
       " 'Working in a stylish, modern and collaborative office close to East Croydon Station',\n",
       " 'Company pension matching and bonus',\n",
       " 'Unrivalled Learning and Development programmes',\n",
       " '',\n",
       " 'Come and be part of something special.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T18:15:29.225890Z",
     "start_time": "2020-07-26T18:15:29.213744Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from skills_ml.ontologies.onet import Onet\n",
    "\n",
    "from skills_ml.job_postings.raw.virginia import VirginiaTransformer\n",
    "from typing import Dict, Text, Any, Generator\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from skills_ml.algorithms.embedding.models import visualize_in_tensorboard\n",
    "\n",
    "from skills_ml.algorithms.skill_extractors import SkillEndingPatternExtractor\n",
    "from skills_ml.job_postings.common_schema import JobPostingCollectionSample\n",
    "from skills_ml.algorithms.skill_extractors import ExactMatchSkillExtractor\n",
    "from skills_ml.algorithms.skill_extractors import SocScopedExactMatchSkillExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T18:22:23.863658Z",
     "start_time": "2020-07-26T18:22:23.852032Z"
    }
   },
   "outputs": [],
   "source": [
    "fname = '50_sample.json'\n",
    "f = open(fname, 'r')\n",
    "data = f.read().split('\\n')[0]\n",
    "json_data = json.loads(data)\n",
    "\n",
    "df_small = df.copy()\n",
    "\n",
    "df_json = []\n",
    "for i in range(df_small.shape[0]):\n",
    "    df_json.append(json_data.copy())\n",
    "    df_json[i]['hiringOrganization']['location'] = df_small['location'][i]\n",
    "    df_json[i]['hiringOrganization']['organizationName'] = df_small['company_name'][i]\n",
    "    df_json[i]['title'] = df_small['job_title'][i]\n",
    "    df_json[i]['jobDescription'] = df_small['section_str'][i].split('\\n')\n",
    "    df_json[i]['responsibilities'] = df_small['summary'][i].split('\\n')\n",
    "    df_json[i]['normalizedTitle']['onetCode'] = df_small['onet_code'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"df_section.json\", \"w\") as write_file:\n",
    "    for i in df_json:\n",
    "        json.dump(i, write_file)\n",
    "        write_file.write('\\n')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology summary statistics for onet\n",
      "Num competencies: 32030\n",
      "Num occupations: 1133\n",
      "Num competency-occupation edges: 107305\n",
      "Median occupations per competency: 1\n",
      "Median competencies per occupation: 89\n",
      "Mean occupations per competency: 3.350245090386837\n",
      "Mean competencies per occupation: 94.70873786407768\n"
     ]
    }
   ],
   "source": [
    "# Prebuilt Ontologies\n",
    "\n",
    "onet = Onet()\n",
    "onet.print_summary_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skills_ml.ontologies.onet.Onet"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(onet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import common schema job posting data\n",
    "\n",
    "## reads json data file\n",
    "\n",
    "JobPostingType = Dict[Text, Any]\n",
    "JobPostingGeneratorType = Generator[JobPostingType, None, None]\n",
    "MetadataType = Dict[Text, Dict[Text, Any]]\n",
    "\n",
    "class JobPostingParser(object):\n",
    "    def __init__(self):\n",
    "        fname = 'df_section.json'\n",
    "        f = open(fname, 'r')\n",
    "        self.lines = f.read().split('\\n')\n",
    "        self.transformer = VirginiaTransformer(partner_id = 'VA')\n",
    "        \n",
    "    def __iter__(self) -> JobPostingGeneratorType:\n",
    "        for line in self.lines:\n",
    "            if line:\n",
    "                yield self.transformer._transform(json.loads(line))\n",
    "\n",
    "job_postings = JobPostingParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_small.copy()\n",
    "\n",
    "df_out['pattern'] = None\n",
    "df_out['exact_match'] = None\n",
    "df_out['soc_scoped'] = None\n",
    "df_out['skills'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "skill_extractor_p = SkillEndingPatternExtractor(only_bulleted_lines=False)\n",
    "skill_extractor_e = ExactMatchSkillExtractor(onet.competency_framework)\n",
    "skill_extractor_s = SocScopedExactMatchSkillExtractor(onet)\n",
    "counter = 0\n",
    "\n",
    "for job_posting in job_postings:\n",
    "    pattern_dict = {}   \n",
    "    em_dict = {}\n",
    "    soc_dict = {}\n",
    "    skills = []\n",
    "    for candidate_skill in skill_extractor_p.candidate_skills(job_posting):\n",
    "        pattern_dict[candidate_skill.skill_name] = candidate_skill.context\n",
    "        skills.append(candidate_skill.skill_name)\n",
    "    df_out['pattern'][counter] = pattern_dict\n",
    "    \n",
    "    for candidate_skill in skill_extractor_e.candidate_skills(job_posting):\n",
    "        em_dict[candidate_skill.skill_name] = candidate_skill.context\n",
    "        skills.append(candidate_skill.skill_name)\n",
    "    df_out['exact_match'][counter] = em_dict\n",
    "    \n",
    "    for candidate_skill in skill_extractor_s.candidate_skills(job_posting):\n",
    "        soc_dict[candidate_skill.skill_name] = candidate_skill.context\n",
    "        skills.append(candidate_skill.skill_name)\n",
    "    df_out['soc_scoped'][counter] = soc_dict\n",
    "    \n",
    "    df_out['skills'][counter] = list(set(skills))\n",
    "    counter += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['self',\n",
       " 'organisation skills',\n",
       " 'communication skills',\n",
       " 'microsoft word',\n",
       " 'c',\n",
       " 'organizational skills']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out.skills[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T16:27:27.102435Z",
     "start_time": "2020-07-26T16:27:27.099132Z"
    }
   },
   "outputs": [],
   "source": [
    "CandidateSkill = namedtuple('CandidateSkill', [\n",
    "    'skill_name',\n",
    "    'matched_skill_identifier',\n",
    "    'context',\n",
    "    'start_index',\n",
    "    'confidence',\n",
    "    'document_id',\n",
    "    'document_type',\n",
    "    'source_object',\n",
    "    'skill_extractor_name'\n",
    "])\n",
    "\n",
    "\n",
    "CandidateSkillYielder = Generator[CandidateSkill, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T16:28:41.692617Z",
     "start_time": "2020-07-26T16:28:41.686030Z"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "class SkillExtractor(object, metaclass=ABCMeta):\n",
    "    \"\"\"Abstract class for all skill extractors.\n",
    "    All subclasses must implement candidate_skills.\n",
    "    All subclasses must define properties\n",
    "    'method' (a short machine readable property)\n",
    "    'description' (a text description of how the extractor does its work)\n",
    "    Args:\n",
    "        transform_func (callable, optional) Function that transforms a structured object into text\n",
    "            Defaults to SimpleCorpusCreator's _join, which takes common text fields\n",
    "            in common schema job postings and concatenates them together.\n",
    "            For non-job postings another transform function may be needed.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.transform_func = transform_func\n",
    "        if not self.transform_func:\n",
    "            self.transform_func = SimpleCorpusCreator()._join\n",
    "        self.nlp = nlp\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def name(self):\n",
    "        \"\"\"A short, machine-friendly (ideally snake_case) name for the skill extractor\"\"\"\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def description(self):\n",
    "        \"\"\"A human-readable description for the skill extractor\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def candidate_skills(self, source_object: Dict) -> CandidateSkillYielder:\n",
    "        \"\"\"Yield objects which may represent skills/competencies from the given source object\n",
    "        Args: source_object (dict) A structured document for searching, such as a job posting\n",
    "        Yields: CandidateSkill objects\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def document_skill_counts(self, source_object: Dict):\n",
    "        \"\"\"Count skills in the document\n",
    "        Args:\n",
    "            source_object (dict) A structured document for searching, such as a job posting\n",
    "        Returns: (collections.Counter) skills found in the document, all\n",
    "            values set to 1 (multiple occurrences of a skill do not count)\n",
    "        \"\"\"\n",
    "        skill_counts = Counter()\n",
    "        for candidate_skill in self.candidate_skills(source_object):\n",
    "            skill_counts[self.nlp.lowercase_strip_punc(candidate_skill.skill_name).lstrip().rstrip()] += 1\n",
    "        return skill_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T16:28:44.295234Z",
     "start_time": "2020-07-26T16:28:44.288189Z"
    }
   },
   "outputs": [],
   "source": [
    "class SectionExtractSkillExtractor(SkillExtractor):\n",
    "    \"\"\"Extract skills from text by extracting sentences from matching 'sections'.\n",
    "    Heavily utilizes skills_ml.algorithms.nlp.section_extract.\n",
    "    For more detail on how to define 'sections', refer to its docstring.\n",
    "    \"\"\"\n",
    "    def __init__(self, section_regex=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.section_regex = section_regex or r'.*([Qq]ualifications|[Ss]kills|[Rr]equirements|[Ab]ilities|[Cc]ompetencies)'\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return f'section_extract_{self.section_regex}'\n",
    "\n",
    "    @property\n",
    "    def description(self):\n",
    "        return f'Sentences from section matching regular expression: {self.section_regex}'\n",
    "\n",
    "    def candidate_skills(self, source_object: Dict) -> CandidateSkillYielder:\n",
    "        \"\"\"Generate candidate skills from the source object\n",
    "        Yields each sentence from the configured section pattern\n",
    "        \"\"\"\n",
    "\n",
    "        spans_in_section = section_extract(self.section_regex, source_object['description'])\n",
    "        for span in spans_in_section:\n",
    "            logging.info('Yielding candidate skill %s', span)\n",
    "            yield CandidateSkill(\n",
    "                skill_name=span.text,\n",
    "                matched_skill_identifier=None,\n",
    "                confidence=100,\n",
    "                context=span.text,\n",
    "                start_index=span.start_index,\n",
    "                document_id=source_object['id'],\n",
    "                document_type=source_object['@type'],\n",
    "                source_object=source_object,\n",
    "                skill_extractor_name=self.name\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T16:30:03.399604Z",
     "start_time": "2020-07-26T16:30:03.395919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object SectionExtractSkillExtractor.candidate_skills at 0x7fb4c2fb85d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SectionExtractSkillExtractor.candidate_skills(units_in_section, source_object={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
